\chapter{Methodology}
\label{chapterlabel4}

This section describes the procedures used to collect data and conduct the analysis that was employed to answer the research question in this study. 

\section{Processing historical OSM data}

Unprocessed OSM historical data extracts for each case study area were downloaded from Geofabrik. \footnote{\url{http://download.geofabrik.de/}} This 'raw' data was then processed using the OpenStreetMap History Database (OSHDB) framework \parencite{raifer_oshdb_2019}. While there are a variety of tools available for investigating OSM history data (such as the \textit{Is OSM Up-To-Date?}\footnote{\url{https://wiki.openstreetmap.org/wiki/Is_OSM_up-to-date}} website developed by \textcite{minghini_open_2018}), OSHDB was selected due to the speed and flexibility that it provides in processing and filtering historical OSM data. Despite these advantages offered by the OSHDB framework, the complexity of OSM history data means that the extraction of relevant variables constituted a significant portion of this methodology. 

To begin, each OSM history extract, in \textit{.osh.pbf} format, was converted to a local OSHDB instance, following the Extract, Transform, Load (ETL) process described in the OSHDB documentation. \footnote{\url{https://github.com/GIScience/oshdb/tree/master/oshdb-tool/etl}} This process loads the data from each extract into separate local H2 databases that are hosted locally. Each OSM entity is transformed into an OSH entity, a data format designed for use within the OSHDB framework. OSH entities allow for more efficient storage of OSM data as they group together different versions of the same entity \parencite{raifer_oshdb_2019}. 

The OSHDB API \parencite{raifer_oshdb_2019} was then used to filter and process the historical data to obtain variables of interest.  Implemented in the Java programming language, this API allows for data filtering and aggregation based on the \textit{MapReduce} programming framework \parencite{raifer_oshdb_2019}. This framework is designed for use with large datasets and contains a \textit{map} function whereby data is filtered and sorted, followed by a \textit{reduce} function whereby data is summarized and returned as aggregated values \parencite{dean_mapreduce_2008}. 

Each history extract was geographically subsetted using a bounding box around the area of interest for each case study. We collected data from one year preceding the start of the humanitarian mapping activation until January 1st, 2020, at weekly intervals. Within this scope, we collected data relating to the volume of contributors, and the volume and type of contributions that were made to OSM. A summary of these variables is contained in Table \ref{tab:vars}. 

%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE 
\begin{table}[ht]
\centering
\caption{Summary of variables extracted from historical OSM data using the OSHDB API}
\label{tab:vars}
\begin{tabular}[t]{ll}
\toprule
Name & Description \\
\midrule
Num\_Contrib    & Number of unique contributors who added data to OSM  \\
Num\_Tag\_Change    & Number of tag change edits to OSM entities \\
Num\_Geom\_Change    & Number of geometry change edits to OSM entities \\
Num\_Creation    & Number of OSM entities created \\
Num\_Deletion    & Number of OSM entities deleted \\
\bottomrule
\end{tabular}
\end{table}%
%%%%%%%%%%%%%%%%%%%%%%%%%%

Following this extraction, the variables in Table \ref{tab:vars} were then processed to calculate further variables of interest, as is detailed in Table \ref{tab:varsproc} below. 

%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE
\begin{table}[ht]
\centering
\caption{Summary of additional calculated variables}
\label{tab:varsproc}
\begin{tabular}[t]{llc}
\toprule
Name & Description & Formula \\
\midrule
Contrib\_Dens    & Density of unique contributors  & e \\
Tot\_Edits    & Total number of edits &  a \\
Per\_Maint    & Percent maintenance edits & b \\
Abs\_Change\_Edits & Week on week absolute change in total edits & e \\
Abs\_Change\_Contrib & Week on week absolute change in total contributors & b \\
\bottomrule
\end{tabular}
\end{table}%
%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Exploring lineage of data production}



\section{Identifying maintenance activities}

