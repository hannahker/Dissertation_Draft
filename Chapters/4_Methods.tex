\chapter{Methodology}
\label{chapterlabel4}

This section describes the procedures used to collect and analyze historical OSM data to address the reseach questions identified in Chapter \ref{chapterlabel1}. I begin by describing the process of selecting case studies and then detail my procedures for collecting and cleaning relevant historical OSM data. I then describe the empirical approach used to analyze and visualize this data to understand characteristics of data production and subsequent data maintenance efforts. I considered each case study (mapping campaign) to be a \textit{unit of analysis}, within which a \textit{unit of observation} was a unique OSM entity that was created during a given mapping campaign. All data processing and analysis was done using the Java and R programming languages. Data visualization was done using R and QGIS. For reproducibility purposes, all code used for data collection and analysis can be accessed from a public GitHub repository.\footnote{\url{https://github.com/hannahker/osm-maintenance}} This repository also includes samples of the data that was used in this analysis. 

\section{Case study approach}

I applied a comparative case study analysis throughout this work, investigating four humanitarian mapping campaigns and one reference case study. Guided by the approach set out in \textcite{kaarbo_practical_1999}, I conducted a focused and structured comparison of cases and looked for patterns in variables within and across cases. I investigated similarities and differences within the humanitarian cases, and between the humanitarian cases and the reference case. This case study approach is appropriate for this project's research aims as it allows us to refine and develop existing theories relating to humanitarian mapping practices \parencite{kaarbo_practical_1999}. Given the lack of existing methodological framework for empirically assessing data maintenance in OSM, this approach was largely exploratory and iterative.

I selected humanitarian case studies that consisted of mapping efforts in response to a humanitarian need, were constrained to subnational geographic areas, drove a sufficient volume of mapping activity on OSM (as defined by volume of unique contributors and volume of edits over time), and were sufficiently documented on community organizing pages such as the OSM Wiki\footnote{\url{https://wiki.openstreetmap.org/wiki/Main_Page}}, HOT Projects page\footnote{\url{https://www.hotosm.org/projects/}}, or HOT Tasking Manager\footnote{\url{https://tasks.hotosm.org/}}. Case studies were also selected with the intent to capture practices of humanitarian mapping at various stages in the history of the humanitarian OSM community. Case studies were also required to have been completed at least four years ago, to allow for the study of maintenance practices in the years following a mapping campaign.  

Following from the above criteria, I focused on humanitarian mapping activities in 1) Port au Prince, Haiti, following the 2010 earthquake, 2) Tacloban, Philippines, following the 2015 typhoon, 3) Bangui, Central African Republic, following 2013 rebellions, and 4) Kathmandu, Nepal, following the 2015 earthquake. In addition to these four humanitarian case studies, I have also selected a reference case study as a contrasting example of mapping activities in a region with established high quality data \parencite{arsanjani_assessing_2013}. Following \textcite{anderson_crowd_2018}, I selected Heidelberg, Germany as the reference case.

\section{Processing historical OSM data}
\label{sec:history}

This analysis is based on historical OSM data, as described in the previous chapter. Unprocessed OSM historical data extracts for each case study area were downloaded from Geofabrik \parencite{geofabrik_openstreetmap_2020}. This "raw" data was then processed using the OSHDB framework \parencite{raifer_oshdb_2019}. OSHDB was selected due to the speed and flexibility that it provides in processing and filtering historical OSM data. Despite these advantages offered by the OSHDB framework, the size and complexity of OSM history data means that the extraction of relevant variables constituted a significant portion of this methodology. The technical approach to processing data, including specific programming approaches, was significantly aided by the examples and documentation provided on the OSHDB GitHub page \parencite{heidelberg_institute_for_geoinformation_technology_oshdb_2020}.

%%%%%%%%%%%%%%%%%%%%%%%%%% Over time image 
\begin{figure} % opens the figure environment. the '[H]' forces the image to be Here
    \centering % puts the image in the horizontal centre of the page
    \includegraphics[width = \textwidth]{Images/Datapipeline.png} %this tells latex what graphics to include. 
    \caption{Summary of data processing pipeline.} % this prints the caption below the figure
    \label{fig:pipe} % this internally labels the figure for future referencing.
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% 

To begin, each OSM history extract, in \textit{.osh.pbf} format, was converted to a local OSHDB instance, following the Extract, Transform, Load (ETL) process described in the OSHDB documentation \parencite{heidelberg_institute_for_geoinformation_technology_setup_2020}. This process loads the data from each extract into separate local H2 databases. Some of the historical extracts were too large to be processed locally in this manner and so technical assistance in generating some extracts was provided by a researcher from the Heidelberg Institute for Geoinformation Technology (HeiGIT) team. 

The OSHDB API \parencite{raifer_oshdb_2019} was then used to filter and process the historical data to obtain variables of interest.  Implemented in the Java programming language, this API allows for data filtering and aggregation based on the \textit{MapReduce} programming framework \parencite{raifer_oshdb_2019}. This framework is designed for use with large datasets and contains a \textit{map} function whereby data is filtered and sorted, followed by a \textit{reduce} function whereby data is summarized and returned as aggregated values \parencite{dean_mapreduce_2008}.

I collected data for each case study using the spatial and temporal extents specified in Table \ref{tab:cases}. Bounding boxes correspond to the smallest square area encompassing the city of interest (here with coordinates rounded to two decimal places for greater legibility). The start and end date for each of the humanitarian featuress was collected from the associated HOT project page, which includes a brief summary of each campaign, along with basic details such as the dates and completion status \parencite{humanitarian_openstreetmap_team_projects_2020}. The start and end dates for the Heidelberg reference case were selected to cover a year-long period that was relatively early in the development of the map for this area, to be better compared against the humanitarian cases. 

%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE 
\begin{table}
\centering
\caption{Details of the spatial and temporal extents used to filter data for each case study.}
\label{tab:cases}
\begin{tabular}{llll}
\toprule
Name                     & Start      & End        & Bounding box                 \\
\midrule
Heidelberg               & 2008-12-31 & 2009-12-31 & 8.57, 49.35, 8.79, 49.46     \\
Port au Prince         & 2010-01-12 & 2011-10-31 & -72.57, 18.34, -72.16, 18.63 \\
Bangui & 2013-03-23 & 2015-12-31 & 18.49, 4.32, 18.59, 4.49     \\
Tacloban           & 2013-11-10 & 2014-01-31 & 124.89, 11.18, 125.08, 11.34 \\
Kathmandu         & 2015-04-25 & 2015-12-31 & 85.27, 27.67, 85.38, 27.75  \\
\bottomrule
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%

For each of the case studies, I focused solely on collecting the attributes from new data that was produced in each campaign. I also focused only on nodes and ways, given that they represent features of humanitarian interest, such as roads, buildings, and healthcare facilities. Using the OSHDB's \textit{stream()} functionality, numerous variables were collected from all OSM features that were created during this time, and all subsequent versions of these features that were created in the time following the mapping campaigns. For example, details would be collected about OSM entity, \textit{Node X}, that was created during the mapping efforts in \textit{Case Study Y}. At its initial creation, \textit{Node X} would have a version \#1. By grouping together all versions of a given OSM entity within a parent OSH entity, the OSHDB data model also allowed us to collect information from all subsequent versions of \textit{Node X} (which are distinct OSM entities themselves). These subsequent versions reflect modifications that were made to \textit{Node X} after it was initially created, such as modifications to its geometry or tags. The variables collected for each OSM entity are summarized in Table \ref{tab:vars}. 

The information captured by these variables is diverse, encompassing numerical, spatial, temporal, and attributional information. While most variables are highly structured, the information contained within the \textit{Tags} variable requires significant cleaning to be useful. Across all case studies, I have collected data from 495,891 OSM entities. Many of these entities reflect subsequent versions of the entities created during each campaign. 

%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE 
\begin{table}
\centering
\caption{Summary of variables collected from OSM entities.}
\label{tab:vars}
\begin{tabular}{lll}
\toprule
Variable       & Description                                                                                    & Data type   \\
\midrule
ID             & Unique identifier for OSM/OSH entity                                                           & Numeric     \\
User ID        & The user ID of the OSM contributor                                                             & Numeric     \\
Bounding box   & Bounding box for the OSH entity                                                                & Coordinates \\
Type           & Node or way                                                                                    & Text        \\
Version number & Version number for the OSM entity                                                              & Numeric     \\
Timestamp      & Time of feature creation                                                                        & Date/time   \\
Tags           & \begin{tabular}[c]{@{}l@{}}Tags and keys associated with the \\ OSM entity\end{tabular}        & Text        \\
Visibility     & \begin{tabular}[c]{@{}l@{}}Indicating whether or not the \\ node has been deleted\end{tabular} & Boolean  \\
\bottomrule
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Exploring the characteristics of data production}
\label{sec-production}

This historical OSM data was then analyzed to understand the basic characteristics of data production for each mapping campaign. Numerous data processing steps were performed to understand how the data was produced over time, where the data was produced over space, what sources contributed to data production, and what types of geographic features were produced. Numerous summary statistics for each case study were also calculated to allow for quantitative comparison.

To understand the dynamics of data production over the duration of each mapping campaign, all features were aggregated by the day that they were produced. I calculated the total number of features produced and the unique number of contributors each day. I then calculated the relationship between these two variables, by day, using the Pearson correlation coefficient. 

I investigated the patterns of data production over space by visualizing the density of new features created within each study area. I created a dot-density map for each case study, as this effectively shows the geographic distribution of contributions in each study area \parencite{kimerling_dotting_2009}. I calculated the centroid from each feature's bounding box to create this point-based density visualization. 

I parsed the tags associated with each feature to understand the types of features that were mapped and their associated sources. While tagging conventions within the OSM community result in many standardized tags used across features, some basic text preprocessing was conducted to ensure that all text was normalized as much as possible, allowing for more accurate aggregation. I converted all characters to lowercase and removed non alpha-numeric characters. For each case study, I calculated the most frequently occurring tag keys (and not the associated values) to provide an indication of the types of features that were mapped. I also analyzed the values that are associated with the \texttt{source} tag key across features. While no longer a common tagging practice, the \texttt{source} tag key has frequently been used within the OSM community as a way to indicate the information source behind a given contribution \parencite{openstreetmap_wiki_keysource_2020}. For example, features that were added to OSM by tracing Bing satellite imagery might be accompanied by the \texttt{source=Bing} key-value pair. I calculated the most frequently occurring source values for each case study to provide an indication of the common information sources. As in \textcite{ahmouda_analyzing_2018}, this information can contribute to an understanding of whether or not a contributor is remote, based on the presence of satellite imagery sources.  

In addition to the above analyses, various metrics were calculated to provide a basis for empirical comparison between case studies. These metrics are summarized in Table \ref{tab:metrics}. I calculated the total duration and size of study area, as well at the total number of unique features mapped and unique contributors. I also follow \textcite{dittus_mass_2017} in calculating the "burstiness" of each case study and classifying each case study as an event or mission. The burstiness measure provides insight into the dynamics of data production and is particularly relevant in the context of humanitarian mapping, as data is often produced very quickly over time in response to a crisis \parencite{dittus_mass_2017}. 

%%%%%%%%%%%%%%%%%%%%%%%%%% TABLE 
% \usepackage{booktabs}


\begin{table}
\centering
\caption{Metrics calculated to compare mapping activity across case studies.}
\label{tab:metrics}
\begin{tabular}{lll} 
\toprule
Metric                    & Unit                                & Formula                                                                                                        \\ 
\midrule
Duration                  & $days$                             & End date - start date                                                                                          \\
Area                      & $km^2$                            & Bounding box length * width                                                                                    \\
Total features created    & $features$                         & NA                                                                                                             \\
Total unique contributors & $contributors$                     & NA                                                                                                             \\
Burstiness                & $days$                             & \begin{tabular}[c]{@{}l@{}}Number of days until 50\% of all \\ contributions were made\\\parencite{dittus_mass_2017}\end{tabular}  \\
Campaign style            & \textit{EVENT} or \textit{MISSION}  & \begin{tabular}[c]{@{}l@{}}Event if burstiness 60, or \\ Mission if burstiness = 60 \\ \parencite{dittus_mass_2017}\end{tabular}     \\
\bottomrule
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%

The analysis described in this section will allow for a greater understanding of the many dimensions of data production during humanitarian mapping campaigns. Comparison between the humanitarian case studies and the Heidelberg reference will allow for the identification of difference and similarity between mapping in humanitarian and non-humanitarian contexts. This understanding will provide valuable context, allow for a more meaningful interpretation of the results of the following section on data maintenance following mapping campaigns.

\section{Identifying data maintenance activities}
\label{sec-maint}

I analyse the historical OSM data for each case study to understand the extent to which features are maintained following each case study mapping campaign. I define data maintenance in OSM to be the practice by which a given feature already existing within the database is updated, presumably to reflect a real-world change that has taken place in the corresponding geographic feature.  For example, following a building renovation, the building's footprint may have changed, requiring updating to the geometry of the building's polygon in OSM. 
I operationalize this definition by following \textcite{quattrone_work_2017}, in considering data maintenance to have occurred any time that an OSM entity has a version greater than 1. This definition leads to a binary consideration of maintenance, in that a given feature is considered to be \textit{unmaintained} if it only has one version (indicating that it has not been modified since its initial creation), and is considered to have been \textit{maintained} if it has at least two versions (indicating that it has been modified at least once since its initial creation). Note that entitiy deletions, in addition to modifications, also result in a new entity version being created. 

In addition to this binary perspective, I consider different degrees of maintenance across features by examining the total number of versions that they each contain. I am thus able to make a distinction not only between maintained and unmaintained features, but also between those that are more frequently maintained than others (ie. those that have a greater number of versions). Based on the distribution of version numbers across all features in the dataset, I create a classification of maintenance frequency, as detailed in Table \ref{tab:freq}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[]
\centering
\caption{Classification scheme of maintenance frequency.}
\label{tab:freq}
\begin{tabular}{ll}
\toprule
Number of versions & Maintenance frequency \\
\midrule
1                  & Never                  \\
2                  & Once                  \\
3-10               & Moderate              \\
11-19              & Frequent              \\
20+                & Extreme               \\
\bottomrule
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%

I also evaluated data maintenance over time, aiming to better understand \textit{when} maintenance occurs following a mapping campaign. To normalize across each of the case studies, I consider the four-year period following each of the mapping campaigns. At cumulative yearly intervals, I calculate the percentage of all features that have been maintained at least once and the distribution of features belonging to each maintenance frequency class in Table \ref{tab:freq}. 

I then conduct a disaggregated evaluation of data maintenance by investigating the types of features that are maintained more frequently than others. I consider differences in the maintenance frequency between nodes and ways. I also consider the differences between features with \texttt{building}, \texttt{highway}, and all other features without either of these tags (all grouped together). I calculate the maintenance frequency distribution for each type of feature after four years have passed since each mapping campaign. 

Following these efforts to quantify data maintenance across each of the case studies, the results are interpreted with respect to the findings from the previous section. I consider the results from Sections \ref{sec-production} and \ref{sec-maint} to develop informed hypotheses about how the modes of data production during humanitarian mapping campaigns may have an impact on the prevalence of data maintenance. Given the limited scope of this work, these hypothesis cannot be empirically validated, and so should be explored in greater depth in future work. 

\section{Ethical considerations}

Following UCL guidelines\footnote{\url{https://ethics.grad.ucl.ac.uk/exemptions.php}}, this project was deemed to be exempt from a formal ethics review as it constitutes a non-invasive and non-interactive observation of public behaviour (editing processes on OSM). This methodology does not involve identifying individuals in any way that could place them at risk of harm, stigma, or prosecution. While this research includes OSM User IDs which may uniquely identify individuals, this analysis considers this data from an entirely aggregated perspective. The sample data that is published on GitHub for reproducibility purposes has been entirely anonymized (all User IDs have been replaced with the integer, 1). 

The historical OSM data used in this research was accessed in accordance with the guidelines set out on the \textit{Geofabrik} download server. This research constitutes a quality assurance effort that is supported by the OSM community (Missing Maps), and does not present any derived works based on these files. 


