\chapter{Discussion}
\label{chapterlabel6}

In this chapter we consider the results of our analysis with respect to our research question and objectives. We interpret these findings with respect to the existing body of literature that was discussed in previous chapter. We discuss the limitations of this research approach and point to potential directions for future work. 

\section{Implications for research objectives}

\noindent\textbf{Objective 1: Evaluate the characteristics of data production during the selected humanitarian mapping activations and compare against the selected reference case.} 

Our results show distinct differences between the humanitarian mapping activations and the Heidelberg reference. It is immediately apparent that the daily volume of data created reaches much higher levels during the humanitarian activations than in Heidelberg. For example, all humanitarian cases have at least one day where over 2000 features were created, while Heidelberg's maximum is only little over 100 contributions in a single day. Mapping efforts in Kathmandu, Port au Prince, and Tacloban also attracted large volumes of contributors on some days (reaching over 150 unique contributors in a single day in Kathmandu, for example), while efforts in Bangui and Heidelberg had less than 10 unique contributors each day. 

The event/mission classification scheme proposed by \textcite{dittus_mass_2017} offers a useful framework for considering data production in humanitarian mapping activations. The early peaks for the event-style activations (Port au Prince, Tacloban, and Kathmandu) shown in Figure \ref{fig:time} clearly demonstrate the dramatic burstiness that occurs when mapping is done urgently in response to an immediate natural disaster. We see that the urgency of these events leads to a rapid and significant decay in contribution volume as time passes. As shown in Figure \ref{fig:scatter}, this decay in contribution volume is correlated with a decay in contributor numbers (as is intuitive). This pattern in mapping activity from event style activations echoes the findings from \textcite[p. 1294]{dittus_mass_2017}.

While both Heidelberg and Bangui are classified as mission-style activations, Figures \ref{fig:time} and \ref{fig:scatter} show notable differences in the dynamics of how data is produced over time. Figure \ref{fig:time} shows that the volume of entities created over time in Heidelberg remains relatively stable, while mapping in Bangui has significant peaks throughout the duration of the activation. It is likely that some of these peaks are the result of data imports. This hypothesis is supported by Figure \ref{fig:scatter}, where we see the relatively weak relationship between the number of daily contributors and the daily volume of contributed data, as some days have over 1000 entities produced by fewer than four contributors. As is described in Chapter \ref{chapterlabel5}, data imports from UNICEF have been documented from this activation. While past works, such as \textcite{ahmouda_analyzing_2018}, aim to remove data imports from their analysis, we consider this to be an important part of the data production landscape that should be considered. Despite these differences, we can see that the mission-style of humanitarian mapping (as represented by the Bangui case study) is more similar to what we would consider as standard practices of OpenStreetMap data production (as represented by the Heidelberg case study) than event-style activations.

A review of the commonly-occurring tags keys shows how features such as buildings and roads are common across all case studies. This is not an unexpected finding, as these tags are among the most frequently used in all of OSM. The TagInfo\footnote{\url{https://taginfo.openstreetmap.org/}} website indicates that 58\% of all ways are tagged with \textit{building} and 24\% of all ways are tagged with \textit{highway}. Table \ref{tab:tags} also shows the different ways that tags are used to label OSM entities, across both our humanitarian and reference cases. Some tags, such as \textit{building} and \textit{highway}, correspond to geographic entities that indicate what the OSM entity is representing. Other tags, such as \textit{source} and \textit{created_by} indicate characteristics of how the data was produced. Our review of the commonly-used \textit{source} tags in Table \ref{tab:sources} shows that many of the entities from our humanitarian cases were produced from satellite sources, indicating that many contributors were remote. The prevalence of remote contributors during humanitarian mapping activations is well-understood within the literature \parencite{dittus_mass_2017, eckle_quality_2015}. While very few of the entities from Heidelberg were tagged with a \textit{source}, we do not see the presence of any satellite sources, indicating that this data was more likely to be produced by local mappers. Interestingly, we also see the presence of disaster-related tags in the humanitarian cases, such as \textit{typhoon:damage, idp:camp_site}, and \textit{damage:event}. These disaster tags correspond to temporary attributes, suggesting that they will likely need to be removed or updated in the future. \\

\noindent\textbf{Objective 2: Empirically assess the extent to which data is maintained after each humanitarian mapping activation.}

In this work we present multiple approaches for quantifying data maintenance following each of our case study mapping activations in OSM. We consider maintenance from both a binary and categorical perspective, acknowledging that a given entity may be updated (ie. maintained) any number of times and thus different degrees of data maintenance can take place. 

Figures \ref{fig:tot}, \ref{fig:dist}, and \ref{fig:types} all show how the data from our Heidelberg reference has been maintained to a significantly greater extent than the data from our humanitarian case studies. Heidelberg is the only case study where over 50\% of the entities have been updated or deleted at least once since being created. This finding is in line with our hypothesis, as we have selected Heidelberg as a reference due to its highly engaged community of mappers and comparatively complete and accurate data. While we are careful not to generalize our findings beyond the case studies that we have selected, this result suggests that OSM data produced from humanitarian mapping efforts may be less maintained than other subsets of the database. Greater effort may thus be needed in ensuring that the data produced in response to humanitarian need is maintained in OSM in the years following the activation. 

These findings may have implications for our understanding of the temporal accuracy of OSM data in areas that have been subjects of humanitarian mapping activations. In Chapter \ref{chapterlabel2}, we discussed how data maintenance can be considered as the process by which OSM data is kept up-to-date. 

Our findings suggest a potential problem with the current mechanisms of data production during humanitarian mapping activations. As is shown by our case studies, these activations may produce an incredibly large volume of data over short periods of time (eg. nearly 40,000 nodes and ways produced in Kathmandu alone in less than one year). While there is no denying that this data is immediately useful in the wake of a disaster, for example, it also presents a challenge in that there is now more data that can potentially be out of date in the future if it is not well maintained. Ideally the data produced during a humanitarian activation is of lasting value to the local community, so care should be taken in how it is maintained.

While stakeholders in the humanitarian mapping community, such as HOT, are well-aware of the importance of engaging local communities of contributors in data production, the justification for doing so is not necessarily framed in terms of data maintenance. 

\noindent\textbf{Objective 3: Consider factors of data production that may have an impact on levels of data maintenance.}

It can logically be assumed that low levels of data maintenance are the result of one of two things: 1) there is no need for maintenance as the underlying geography of a given region remains the same, or 2) there is no one with the necessary skills or motivation to do the work involved in maintaining data. 

\noindent\textbf{Objective 4: Distill key findings into recommendations for the humanitarian mapping community.}

\section{Limitations and directions for future work}

The novelty of our research aims posed a challenge in that we were unable to rely on an established analytical workflow for our data processing efforts. The existing literature does not offer an established analytical framework for investigating characteristics of data production and data maintenance during humanitarian mapping activations. We deemed commonly-used spatio-temporal data mining techniques; such as clustering, pattern recognition, and predictive learning; to be inappropriate for our dataset and research aims. 

We note that, as indicated by the approach taken in \textcite{mooney_characteristics_2012}, a higher number of versions for a given entity may not correspond to our definition of maintenance. Many versions may also correspond to cases where the entity needs to be revised, perhaps due to errors made in the initial mapping efforts or to disagreements in how the entity should best be mapped. In the case of humanitarian mapping, the \textit{validation} process also requires that features be reviewed, which may result in new, corrected versions for a given entity (which is, again, not necessarily maintenance). 

Given the little past work in this domain, it is difficult to know how much data maintenance is necessary in a given area. Theoretically, we understand that data only needs to be maintained if the associated geographic phenomena have changed in some way. We assume that it is incredibly unlikely for all geographic phenomena in an area to remain the same over a long period of time, so we understand that, given the passing of time, some data maintenance will always be necessary. However, given that we have no ‘ground-truth’ for how much change has occurred in a given area, it is challenging to know whether or not an apparently lack of data maintenance is a problem or not.  

