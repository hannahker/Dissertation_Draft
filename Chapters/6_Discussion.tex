\chapter{Discussion}
\label{chapterlabel6}

In this chapter, I interpret the results of the analysis described in the previous chapter and consider their implications with respect to the existing body of literature discussed in Chapter \ref{chapterlabel2}. I then reflect on the limitations of this research approach. 
\section{Addressing research questions}

\noindent\textbf{RQ 1: What are the characteristics of data production in the selected humanitarian mapping campaigns and how does this compare with the reference case study?} 

These results show distinct differences between the humanitarian mapping campaigns and the Heidelberg reference. It is immediately apparent that the daily volume of data created reaches much higher levels during the humanitarian campaigns than in Heidelberg. For example, all humanitarian cases have at least one day where over 2000 features were created, while Heidelberg's maximum is only little over 100 contributions in a single day. Mapping efforts in Kathmandu, Port au Prince, and Tacloban also attracted large volumes of contributors on some days (reaching over 150 unique contributors in a single day in Kathmandu, for example), while efforts in Bangui and Heidelberg had less than 10 unique contributors each day. 

The event/mission classification scheme proposed by \textcite{dittus_mass_2017} offers a useful framework for considering data production in humanitarian mapping campaigns. The early peaks for the event-style campaigns (Port au Prince, Tacloban, and Kathmandu) shown in Figure \ref{fig:time} clearly demonstrate the dramatic burstiness that occurs when mapping is done urgently in response to an immediate natural disaster. The urgency of these events leads to a rapid and significant decay in contribution volume as time passes. As shown in Figure \ref{fig:scatter}, this decay in contribution volume is correlated with a decay in contributor numbers (as is intuitive). This pattern in mapping activity from event style campaigns echoes the findings from \textcite[p. 1294]{dittus_mass_2017}.

While both Heidelberg and Bangui are classified as mission-style campaigns, Figures \ref{fig:time} and \ref{fig:scatter} show notable differences in the dynamics of how data is produced over time. Figure \ref{fig:time} shows that the volume of features created over time in Heidelberg remains relatively stable, while mapping in Bangui has significant peaks throughout the duration of the campaign. It is likely that some of these peaks are the result of data imports. This hypothesis is supported by Figure \ref{fig:scatter}, where the relatively weak relationship between the number of daily contributors and the daily volume of contributed data, as some days have over 1000 features produced by fewer than four contributors. As is described in Chapter \ref{chapterlabel5}, data imports from UNICEF have been documented from this campaign. While past works, such as \textcite{ahmouda_analyzing_2018}, aim to remove data imports from their analysis, I consider this to be an important part of the data production landscape that should be considered. Despite these differences, the mission-style of humanitarian mapping (as represented by the Bangui case study) is more similar to what I would consider as standard practices of OpenStreetMap data production (as represented by the Heidelberg case study) than event-style campaigns.

A review of the commonly-occurring tags keys shows how features such as buildings and roads are common across all case studies. This is not an unexpected finding, as these tags are among the most frequently used in all of OSM. The TagInfo website indicates that 58\% of all ways are tagged with \texttt{building} and 24\% of all ways are tagged with \texttt{highway} \parencite{noauthor_openstreetmap_2020}. Table \ref{tab:tags} also shows the different ways that tags are used to label OSM entities, across both the humanitarian and reference cases. Some tags, such as \texttt{building} and \texttt{highway}, correspond to geographic features that indicate what the OSM entity is representing. Other tags, such as \texttt{source} and \texttt{created_by} indicate characteristics of how the data was produced. The review of the commonly-used \texttt{source} tags in Table \ref{tab:sources} shows that many of the features from the humanitarian cases were produced from satellite sources, indicating that many contributors were remote. The prevalence of remote contributors during humanitarian mapping campaigns is well-understood within the literature \parencite{dittus_mass_2017, eckle_quality_2015}. While very few of the features from Heidelberg were tagged with a \texttt{source}, there are not any frequently occurring satellite sources, indicating that this data was more likely to be produced by local mappers. The presence of disaster-related tags in the humanitarian cases, such as \texttt{}{typhoon:damage, idp:camp_site}, and \texttt{damage:event}, is also notable. These disaster tags correspond to temporary attributes, suggesting that they will likely need to be removed or updated in the future. \\

\noindent\textbf{RQ 2: To what extent is the data produced during the selected campaigns maintained over time and how does this compare with the reference case study?}

In this work I present multiple approaches for quantifying data maintenance following each of the case study mapping campaigns in OSM. I consider maintenance from both a binary and categorical perspective, acknowledging that a given feature may be updated (ie. maintained) any number of times and thus different degrees of data maintenance can take place. 

Figures \ref{fig:tot}, \ref{fig:dist}, \ref{fig:types}, and \ref{fig:feats} all show how the data from the Heidelberg reference has been maintained to a significantly greater extent than the data from the humanitarian case studies. Heidelberg is the only case study where over 50\% of the features have been updated or deleted at least once since being created. This finding is in line with expectations, as Heidelberg was selected as a reference due to its comparatively complete and accurate data \parencite{arsanjani_assessing_2013}. While I am careful not to generalize these findings beyond the selected case studies, this result suggests that OSM data produced from humanitarian mapping efforts may be less maintained than other regions of the database. Greater effort may thus be needed in ensuring that the data produced in response to humanitarian need is maintained in OSM in the years following the campaign. 

These findings may have implications for our understanding of the temporal accuracy of OSM data in areas with humanitarian mapping campaigns. In Chapter \ref{chapterlabel2}, I discussed how data maintenance can be considered as the process by which OSM data is kept up-to-date. Thus, it can be assumed that the case studies found to have poorly maintained data, such as in Tacloban and Bangui, may be more likely to have data that is out of date. With reference to the values in Figure \ref{fig:tot} and Table \ref{tab:summary}, one could estimate that over 17,000 features on the map in Tacloban may be out of date.

This approach to understanding temporal accuracy advances existing work by considering not only the attributes of a given feature within OSM at a given point in time (as in \textcite{barron_comprehensive_2014}, who look at the date of last edit), but also the entire lineage of that feature over its history. This approach acknowledges the ongoing evolution of data within OSM, leading to a deeper understanding of its temporal dimensions. 

However, it is difficult to identify the amount of data maintenance that is necessary in a given area to keep OSM data up to date. Theoretically, it can be understood that data only needs to be maintained if the associated geographic phenomena have changed in some way. It is assumed to be incredibly unlikely for all geographic phenomena in an area to remain the same over a long period of time, so given the passing of time, some data maintenance will always be necessary. However, given that this research has no "ground-truth" for how much change has occurred in a given area, it is challenging to know whether or not an apparent lack of data maintenance is a problem. However, the Heidelberg reference case offers an indication of data maintenance levels that might be appropriate. As the OSM data from Heidelberg is generally considered to be of high quality, one might assume that the levels of maintenance seen here are what other regions on the map should strive to achieve. Nevertheless, it is acknowledged that data maintenance needs may vary significantly across different locations \parencite{quattrone_work_2017}. The prevalence of temporally-sensitive tags such as, \texttt{typhoon: damage} and \texttt{damage:event}, in the data from Tacloban may suggest that OSM data produced during humanitarian mapping campaigns may in fact be in need of more maintenance than other parts of the map. 

Ultimately, this work's findings suggest a potential shortcoming with current mechanisms of data production during humanitarian mapping campaigns. As is shown by the case studies, these campaigns may produce an incredibly large volume of data over short periods of time (eg. nearly 40,000 nodes and ways produced in Kathmandu alone in less than one year). While there is no denying that this data is immediately useful in the wake of a disaster, it also presents a challenge in that there is now more data that can potentially be out of date in the future if it is not well maintained. Ideally the data produced during a humanitarian campaign is of lasting value to the local community. This work's results highlight a potential need for more formal mechanisms to ensure data maintenance takes place following humanitarian mapping campaigns.\\

\noindent\textbf{RQ 3: What insight do the results offer into potential relationships between characteristics of data production and levels of data maintenance in each of the case studies?}

Looking across the results previously discussed in this section, I generate informed hypotheses about potential relationships between characteristics of data production and levels of data maintenance. Given the limited volume of case studies under consideration, I acknowledge that these hypotheses may not generalize to other contexts. Rather, my intent is to synthesize these empirical findings with existing theory to offer well-considered suggestions for future research into factors that are associated with greater data maintenance. 

Figures \ref{fig:time} and \ref{fig:scatter} demonstrate how the Heidelberg and Bangui case studies, the two mission-style campaigns, have notably different dynamics of data production and volumes of contributor engagement than the other case studies. One might then expect to see these two campaigns exhibit characteristics of data maintenance that similarly set them apart from the other event-style case studies. However, while Heidelberg is clearly distinct in its high levels of maintenance, Bangui shows characteristics of maintenance that are quite similar to Tacloban (as demonstrated in Figures \ref{fig:tot} and \ref{fig:dist}). This finding may suggest that a mapping campaign’s style (event or mission) may not be an indication of the extent to which the data will be maintained over time. However, future research here is needed. 

The higher levels of data maintenance seen in Heidelberg can perhaps be explained by the low but sustained levels of editing activity conducted by likely local contributors, as shown in Figure \ref{fig:time} and Table \ref{tab:sources}. The overall volume of data produced in Heidelberg is also an order of magnitude less than in all humanitarian case studies. Practically speaking, it is likely easier to keep less data up-to-date. One can also assume that local contributors are more invested in the sustained accuracy of OSM data for their community, and so will work to keep it up-to-date. One might assume that the low but sustained activity shown in Figure \ref{fig:time} indicates the presence of an active local OSM community, which is then a potential indicator of future maintenance efforts taking place. 

This hypothesis is also supported by the past work of  \textcite{quattrone_work_2017}, who find that OSM data is better maintained in areas with more experienced and active contributors. Humanitarian mapping subjects, such as our case studies here, have been found to have significant percentages of newcomer mappers (for example, over 80\% in the Nepal earthquake) \parencite{dittus_mass_2017}. 

Within the humanitarian case studies, Port au Prince and Kathmandu stand out for their higher levels of maintenance. Both the Kathmandu and Port au Prince cases have been documented as having significant local engagement \parencite{soden_crowdsourced_2014}, which may in part explain why this data has been maintained more over time. Compared against mapping in Tacloban, Kathmandu and Port au Prince took place over longer periods of time and engaged more unique contributors. Tacloban had the lowest levels of data maintenance and was the case study with the shortest ‘burst’ value. This data was produced incredibly quickly, which may indicate that less effort was made in engaging with local mappers who would take care of it over time. 

\section{Project limitations}

While the results of this analysis offer insight into data production and maintenance during humanitarian mapping campaigns, it is acknowledged that this work is subject to a number of limitations. 

Firstly, using OSM entity version numbers as indications of maintenance may not be wholly accurate. As indicated by the work of \textcite{mooney_characteristics_2012}, a higher number of versions for a given feature may not be entirely aligned with this work's definition of maintenance. The authors identify, for example, how disagreements between contributors may lead to a back and forth of revisions to a given feature in quick succession \textcite{mooney_characteristics_2012}. While such a conflict undoubtedly indicates that care is given to the quality of this  feature, it might not be accurate to say that a feature with 20 versions as result of such an "edit war" is more maintained than a feature with only 3 versions. This shortcoming could be addressed in future work by more closely investigating the timing between revisions of a given OSM entity. 

Secondly, this work does not distinguish between the different forms of data maintenance that can occur. As is described by \textcite{quattrone_work_2017}, maintenance is constituted of activities including entity deletion, tag removal, and tag addition. A more detailed typology of feature changes in geographic datasets is also provided by \textcite{rehrl_towards_2015}. While it is out of the scope of this work to disaggregate the analysis by these different activities, such an effort may be a meaningful basis for future work. This disaggregated analysis may be supported by the OSHDB framework, which distinguishes between different contribution types within OSM (creations, deletions, tag changes, and geometry changes) \parencite{heidelberg_institute_for_geoinformation_technology_oshdb_2020}. 

Thirdly, the generalizability of these research findings is limited by this work's tightly-scoped case study approach. Given the lack of established methodological framework in this domain, a small number of cases were selected to allow for a more exploratory and descriptive investigation. This work's conclusions are thus only valid within the context of the four humanitarian case studies and one reference case study. It is hoped that this methodology can be repeated across a wider range of humanitarian mapping campaigns, leading to a stronger understanding data maintenance across the entire domain of humanitarian mapping. 



