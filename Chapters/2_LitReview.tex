\chapter{Literature Review}
\label{chapterlabel2}

In this literature review, we will introduce the OpenStreetMap project, situating it within the broader phenomena of volunteered geographic information, neogeography, and Web 2.0. We will then address key issues relating to data quality in OSM and review the large volume of past work that has addressed this topic. We highlight the trend of work that has moved from extrinsic to intrinsic quality assessments and identify a need to address temporal accuracy of data in greater depth. We next focus more closely on the issue of temporal accuracy in OSM and discuss the dynamics of editing. We then focus on the case of humanitarian mapping and discuss the applications of OSM in humanitarian contexts and the unique modes of data production in this domain. We conclude by situating the work of this thesis in the research gap that exists at the intersection of data maintenance, as a dimension of temporal data quality, and humanitarian mapping efforts. 

\section{Introduction to OSM}

OSM is a primary example of what \textcite{goodchild_citizens_2007} terms, "volunteered geographic information" (VGI). VGI sits under the umbrella of "neogeography", in which the democratization of tools for geospatial data production and consumption lead to a wealth of citizen-generated geospatial datasets \parencite{goodchild_neogeography_2009, haklay_web_2008}. More broadly, neogeography is enabled by the rise of the Web 2.0, in which the lines between content production and content consumption on the web are blurred \parencite{oreilly_what_2009}. 

Often framed as the "Wikipedia of maps", OSM values citizens' local knowledge and seeks to empower individuals to share their local spatial knowledge with the wider community. Theoretically, anyone with access to the internet can contribute to OSM. At the time of writing, OSM has over 6 million registered users (although it is likely that not all users have contributed data) and almost 8 billion uploaded GPS points \parencite{noauthor_openstreetmap_2020}. OSM offers a free alternative to proprietary geospatial datasets, and is used for purposes such as vehicle routing \parencite{graser_is_2015, luxen_real-time_2011} and POI searching \parencite{ruta_indooroutdoor_2015}. The OSM contribution landscape is also very heterogeneous. Increasingly, large-scale, existing geospatial datasets can be imported into OSM, such as the US TIGER import in 2008 \parencite{zielstra_assessing_2013}. Moreover, corporate entities; such as Facebook, Microsoft, and Apple; are also increasingly involved in mapping efforts \parencite{anderson_corporate_2019}.

\section{Data Quality and OSM}

As a crowdsourced dataset, one of the primary potential issues with OSM is its quality. OSM does not provide any assurances of its quality, unlike traditional, authoritative geospatial datasets. Moreover, its contributors do not require any formal training or qualifications. Questions of data quality are also particularly relevant and challenging to address in this context because of the highly diverse nature of contributions and contributors, leading to variable quality throughout  \parencite{grochenig_digging_2014, haklay_how_2010, neis_analyzing_2012, girres_quality_2010}. 

Existing literature identifies numerous dimensions that should be considered within the concept of geospatial data quality. Dimensions such as completeness, logical consistency, positional accuracy, temporal accuracy (or currentness), and usability are frequently addressed \parencite{fox_notion_1994, antoniou_measures_2015, van_oort_spatial_2006}. Questions of VGI data quality are also framed around the concepts of trust and credibility, reminding one of the presence of the data user who must evaluate the fitness of the data for their task at hand \parencite{flanagin_credibility_2008, severinsen_vgtrust_2019}. While a characteristic such as positional accuracy can be empirically evaluated, trust and credibility are more perceptual qualities of a dataset that relate to its 'believability' in the eyes of the data consumer \parencite{flanagin_credibility_2008}. \textcite{barron_comprehensive_2014} also address the notion of fitness for use in their consideration of geospatial data quality, demonstrating how different applications of a given dataset will require different quality needs. 

The framework laid out by \textcite{goodchild_assuring_2012} is particularly useful in understanding the mechanisms for quality control in VGI projects. The authors outline the following three approaches: 1) the \textit{crowdsourcing approach}, as evaluated by \textcite{haklay_how_2010-1}, by which a community of contributors will converge on the 'truth' and correct the errors of others; 2) the \textit{social approach}, by which contributors are organized in a hierarchy with those at the top acting as content moderators or gatekeepers; and the 3) \textit{geographic approach}, by which common-sense rules about the nature of geographic phenomena are used to filter out clear errors. From these approaches, we can see that the community structure of VGI projects, such as OSM, can contribute to enhanced quality control, however additional technical checks and evaluation may be needed.

Efforts to empirically assess the quality of OSM data began with what is termed 'extrinsic' approaches, whereby OSM data is compared against an authoritative dataset of assumed high quality. \textcite{haklay_how_2010} compares the completeness and positional accuracy of OSM data in England with that from the Ordnance Survey. \textcite{girres_quality_2010} extend this analysis to the French OSM dataset and \textcite{zielstra_comparative_2010} compare OSM data in Germany to that from the TeleAtlas MultiNet dataset. Overall, these works find OSM data to be of relatively high quality, however quality can also be quite variable across both geographic space and across the different elements of geospatial data quality. For example, \textcite{zielstra_comparative_2010} find significant differences in completeness between urban and rural areas in Germany, with rural areas needing greater coverage. Given that the above work was completed relatively early in the development of OSM (within 6 years of the project beginning), the focus was mostly on completeness of coverage and volume of data.  

More recent efforts to assess OSM data quality are trending towards 'intrinsic' quality assessments. Such efforts can be defined as "process-based measures focusing on pragmatic or contextual ‘authority’ by examining the processes generating information" \parencite[p. 297]{anderson_crowd_2018}. Intrinsic efforts may be preferable due to factors such as the potential high cost of obtaining proprietary datasets, or the lack of availability of such reference datasets \parencite{estes_maps_1994}. Intrinsic quality assessment may also be more appropriate as we acknowledge that authoritative, reference datasets may not be of sufficiently high quality themselves, as suggested by \textcite[p. 112]{goodchild_assuring_2012}. \textcite{barron_comprehensive_2014}, for example, create the \textit{iOSMAnalyzer} tool, which combines over data quality 25 indicators that are tailored to different application areas. 

\section{Temporal data quality and the evolution of OSM data}
\section{OSM production and use in humanitarian contexts}
\section{Conclusions}

