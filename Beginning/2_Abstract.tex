\begin{abstract} % 300 word limit

Humanitarian mapping campaigns have the capacity to produce large volumes of openly available geospatial data in OpenStreetMap (OSM) following a crisis. For regions lacking in authoritative geospatial data, OSM can be a valuable resource for first responders. However, OSMâ€™s crowd-produced nature and lack of formal mechanisms for quality control often raise questions around its trustworthiness and credibility. This work focuses particularly on the issue of temporal accuracy (or up-to-dateness) of OSM data. This work empirically evaluates the extent to which data produced during humanitarian mapping campaigns has been maintained over time. A comparative case study approach is employed, whereby four humanitarian cases; from Haiti, Kathmandu, the Central African Republic, and the Philippines; are compared between each other and against a reference case study of known high data quality; Heidelberg, Germany. The newly developed OpenStreetMap History Database (OSHDB) framework, developed by \textcite{raifer_oshdb_2019}, is applied to filter and process large volumes of historical OSM data. When compared against Heidelberg, it is found that the data produced during humanitarian campaigns is generally poorly maintained over time. Four years after the conclusion of each campaign, the majority of all data has not been updated or deleted, leaving it at risk of being out of date. These findings suggest that formal mechanisms or incentives for data maintenance should be integrated into humanitarian mapping processes.  

\end{abstract}